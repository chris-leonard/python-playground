{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab1076e-2bf4-45ea-9c3d-ba161060c992",
   "metadata": {},
   "source": [
    "# Coefficent of Determination $R^2$\n",
    "\n",
    "## Definition\n",
    "\n",
    "The *Coefficient of Determination* measures the proportion of variation in the regression target that is explained by the model.\n",
    "\n",
    "Given inputs $\\mathbf{x}=(x_1, \\ldots, x_n)$, targets $\\mathbf{y}=(y_1,\\ldots, y_n)$ and predictions $\\mathbf{\\hat{y}}=(\\hat{y}_1,\\ldots, \\hat{y}_n) = (f(x_1), \\ldots, f(x_n))$, the *coefficient of determination* is\n",
    "\n",
    "\\begin{equation}\n",
    "    R^2 = 1 - \\frac{ \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }{ \\sum_{i=1}^n (y_i - \\overline{y}_i)^2 }.\n",
    "\\end{equation}\n",
    "\n",
    "That is, one minus the residual sum-of-squares over the total sum-of-squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb7f22-d5c0-482f-aa35-d239fc35e635",
   "metadata": {},
   "source": [
    "## Properties\n",
    "\n",
    "- Most models have $0\\leq R^2\\leq 1$, but $R^2$ can be arbitrarily negative corresponding to arbitrarily bad predictions\n",
    "- In an ordinary least-squares model, $R^2$ equals Pearson's correlation coefficient between the predictions $\\mathbf{\\hat{y}}$ and the observations $\\mathbf{y}$\n",
    "- In an ordinary least-squares model, $R^2$ can be rewritten as the quotient of the *explained* sum-of-squares by the total sum-of-squares:\n",
    "\n",
    "\\begin{equation}\n",
    "    R^2 = \\frac{ \\sum_{i=1}^n (\\hat{y}_i - \\overline{y})^2 }{ \\sum_{i=1}^n (y_i - \\overline{y})^2 }.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9de2da-9786-4b67-b55e-989bec633758",
   "metadata": {},
   "source": [
    "## Interpretations\n",
    "\n",
    "- Unexplained Variance: $R^2$ is one minus the *Fraction of Variance Unexplained* (FVU); the fraction of the variation in $\\mathbf{y}$ that isn't explained (isn't correctly predicted) from the $\\mathbf{x}$\n",
    "- Comparison with Base Error Rate: $R^2$ compares $f$ against predicting each $y_i$ using the sample mean. If $R^2 = 0$ then the model is no better than predicting using the mean. If $R^2=1$ then the model is perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456b04d-bdbb-4541-995c-551f17001dad",
   "metadata": {},
   "source": [
    "## Drawbacks\n",
    "\n",
    "- With an ordinary least-squares model, $R^2$ is monotone increasing with the number of features, so relying on $R^2$ alone can lead to overfitting\n",
    "- The $R^2$ doesn't indicate whether a model is appropriate, e.g. OLS models yield the same $R^2$ on all members of Anscombe's quarter\n",
    "- The $R^2$ reflects not only the quality of the regression, but also the distribution of the independent variables.\n",
    "- The $R^2$ is very dependent on the number of independent variables, so can't be used a meaningful comparison of models with significantly different numbers of independent variables\n",
    "\n",
    "To illustrate the last two points, suppose that $X$ and $Y$ are random variables with $Y=a+bX +\\epsilon$, where $\\epsilon \\sim \\mathcal{N}\\left(0, \\sigma^2\\right)$ is random noise (independent of $X$). Then the expected value of $R^2$ is\n",
    "\n",
    "\\begin{equation}\n",
    "    1 - \\frac{\\text{E}(\\epsilon^2)}{\\text{Var}(Y)} = 1 - \\frac{\\sigma^2}{b^2 \\text{Var}(X) + \\sigma^2} = \\frac{b^2 \\text{Var}(X)}{b^2 \\text{Var}(X) + \\sigma^2}.\n",
    "\\end{equation}\n",
    "\n",
    "Note that even with a perfect model the value of $R^2$ can be anything in $(0, 1)$ and is entirely dependent on the variation in the independent variable and the inherent noise. Conversely a linear model can achieve $R^2$ close to 1 even with noticeably non-linear data ([example](https://stats.stackexchange.com/a/13317)).\n",
    "\n",
    "See [here](https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/10/lecture-10.pdf) for a list of issues with $R^2$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
